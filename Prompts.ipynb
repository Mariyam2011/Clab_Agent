{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Prefer Pydantic v2\n",
    "    from pydantic import BaseModel, Field\n",
    "except Exception:\n",
    "    # Fallback for older stacks (not recommended for new code)\n",
    "    from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_templates.narratives import create_narrative_angles_prompt_template\n",
    "from prompt_templates.Future_plan import create_future_plan_prompt_template\n",
    "from prompt_templates.Activity import create_activity_list_generator_prompt_template\n",
    "from prompt_templates.Main_essay import create_main_essay_ideas_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from tools import (\n",
    "    generate_narrative_angles,\n",
    "    generate_future_plan,\n",
    "    generate_activity_list,\n",
    "    generate_main_essay_ideas,\n",
    "    route_tool_call,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"clab_data\"\n",
    "# applications_data = []\n",
    "\n",
    "# # Get all JSON files in the folder\n",
    "# for file_path in glob(os.path.join(folder_path, \"*.json\")):\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         applications_data = json.load(f)\n",
    "# print(f\"Loaded {len(applications_data)} applications from {len(glob(os.path.join(folder_path, '*.json')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"clab_data/all_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     applications_data = json.load(f)\n",
    "\n",
    "# print(f\"Loaded {len(applications_data)} applications from all_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class Application:  # This will store accepted applications as well as their embeddings\n",
    "#     filename: str\n",
    "#     content: Dict[str, Any]\n",
    "#     embedding: List[float] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applications = []\n",
    "\n",
    "# for key, application in applications_data.items():\n",
    "#     embedding = embeddings_model.embed_query(json.dumps(application))\n",
    "\n",
    "#     application = Application(\n",
    "#         filename=key,\n",
    "#         content=application,\n",
    "#         embedding=embedding,\n",
    "#     )\n",
    "\n",
    "#     applications.append(application)\n",
    "\n",
    "# with open(\"application_embeddings.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(applications, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applications = pickle.load(open(\"application_embeddings.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMMY_USER_DATA = {\n",
    "    \"name\": \"Sarah Johnson\",\n",
    "    \"gender\": \"Female\",\n",
    "    \"birth_country\": \"United States\",\n",
    "    \"cultural_background\": [\n",
    "        \"American\",\n",
    "        \"first-generation college student\",\n",
    "        \"rural upbringing\",\n",
    "        \"STEM-focused\",\n",
    "        \"environmental advocate\",\n",
    "    ],\n",
    "    \"academic\": {\n",
    "        \"gpa\": \"3.95\",\n",
    "        \"school_type\": \"Public High School\",\n",
    "        \"test_scores\": {\"SAT\": \"1450\", \"ACT\": \"32\"},\n",
    "    },\n",
    "    \"activities\": [\n",
    "        {\n",
    "            \"position\": \"President\",\n",
    "            \"category\": \"Academic\",\n",
    "            \"description\": \"Led environmental science club, organized community clean-up events, coordinated with local government on sustainability initiatives\",\n",
    "        },\n",
    "        {\n",
    "            \"position\": \"Team Captain\",\n",
    "            \"category\": \"Athletics\",\n",
    "            \"description\": \"Varsity soccer team captain, led team to state championship, organized team community service projects\",\n",
    "        },\n",
    "        {\n",
    "            \"position\": \"Volunteer\",\n",
    "            \"category\": \"Community Service\",\n",
    "            \"description\": \"Tutored underprivileged students in math and science, developed curriculum for after-school program\",\n",
    "        },\n",
    "        {\n",
    "            \"position\": \"Research Assistant\",\n",
    "            \"category\": \"Research\",\n",
    "            \"description\": \"Assisted professor in environmental impact study, analyzed data on renewable energy adoption in rural communities\",\n",
    "        },\n",
    "    ],\n",
    "    \"future_plans\": [\n",
    "        \"Study environmental engineering\",\n",
    "        \"Work on renewable energy solutions\",\n",
    "        \"Masters degree\",\n",
    "        \"Start a non-profit focused on rural sustainability\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_embedding = embeddings_model.embed_query(json.dumps(DUMMY_USER_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities = []\n",
    "\n",
    "# for app in applications:\n",
    "#     similarity = cosine_similarity([user_embedding], [app.embedding])[0][0]\n",
    "#     similarities.append((app, similarity))\n",
    "\n",
    "# top_3_similar = sorted(similarities, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "# print(\"Top 3 Accepted Applications:\")\n",
    "# print(\"\\n\".join([each[0].filename for each in top_3_similar]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application_narratives = []\n",
    "\n",
    "# for each in top_3_similar:\n",
    "#     temp = each[0].content\n",
    "\n",
    "#     if \"application_narrative\" in temp:\n",
    "#         application_narratives.append(temp[\"application_narrative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an elite admissions strategist. \"\n",
    "            \"ONLY call the router tool `route_tool_call(user_request, user_profile)` once per user request. \"\n",
    "            \"Never call other tools directly. \"\n",
    "            \"Pass the user's request verbatim as `user_request`, and always include `user_profile`. \"\n",
    "            \"The router will selectively call the appropriate tool and handle dependencies (e.g., auto-generate narrative before future plan). \"\n",
    "            \"Return the router's output as the final answer.\"\n",
    "        ),\n",
    "        (\"user\", \"USER_PROFILE(JSON): {user_profile}\\n\\nTASK: {input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Only expose the router tool to the agent to prevent direct multi-tool calls\n",
    "tools = [\n",
    "    route_tool_call,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are an elite admissions strategist. \"\n",
    "#             \"When calling any tool, ALWAYS include the `user_profile` argument. \"\n",
    "#             \"Follow this strict sequence: \"\n",
    "#             \"1) generate_narrative_angles(user_profile) \"\n",
    "#             \"2) generate_future_plan(user_profile, narrative=<first angle>) \"\n",
    "#             \"3) generate_activity_list(user_profile, narrative=<first angle>, future_plan) \"\n",
    "#             \"4) generate_main_essay_ideas(user_profile, narrative=<first angle>, future_plan, activity_result). \"\n",
    "#             \"Return the final JSON from the last tool.\",\n",
    "#         ),\n",
    "#         (\"user\", \"USER_PROFILE(JSON): {user_profile}\\n\\nTASK: {input}\"),\n",
    "#         MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# tools = [\n",
    "#     generate_narrative_angles,\n",
    "#     generate_future_plan,\n",
    "#     generate_activity_list,\n",
    "#     generate_main_essay_ideas,\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"input\",\n",
    ")\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://clabai3366454354.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `route_tool_call` with `{'user_request': 'Generate future plan for this student', 'user_profile': {'name': 'Sarah Johnson', 'gender': 'Female', 'birth_country': 'United States', 'cultural_background': ['American', 'first-generation college student', 'rural upbringing', 'STEM-focused', 'environmental advocate'], 'academic': {'gpa': '3.95', 'school_type': 'Public High School', 'test_scores': {'SAT': '1450', 'ACT': '32'}}, 'activities': [{'position': 'President', 'category': 'Academic', 'description': 'Led environmental science club, organized community clean-up events, coordinated with local government on sustainability initiatives'}, {'position': 'Team Captain', 'category': 'Athletics', 'description': 'Varsity soccer team captain, led team to state championship, organized team community service projects'}, {'position': 'Volunteer', 'category': 'Community Service', 'description': 'Tutored underprivileged students in math and science, developed curriculum for after-school program'}, {'position': 'Research Assistant', 'category': 'Research', 'description': 'Assisted professor in environmental impact study, analyzed data on renewable energy adoption in rural communities'}], 'future_plans': ['Study environmental engineering', 'Work on renewable energy solutions', 'Masters degree', 'Start a non-profit focused on rural sustainability']}}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://clabai3366454354.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://clabai3366454354.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mEnvironmental engineer designing renewable energy systems to power underserved rural communities.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Environmental engineer designing renewable energy systems to power underserved rural communities.\n"
     ]
    }
   ],
   "source": [
    "resp = executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Generate future plan for this student\",\n",
    "        \"user_profile\": DUMMY_USER_DATA,\n",
    "    }\n",
    ")\n",
    "print(resp[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = executor.invoke(\n",
    "#     {\n",
    "#         \"input\": \"Generate future plan for this student\",\n",
    "#         \"user_profile\": DUMMY_USER_DATA,\n",
    "#     }\n",
    "# )\n",
    "# print(resp[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from workflow_orchestrator import generate_application_strategy\n",
    "\n",
    "# # Use the orchestrator instead of individual chains\n",
    "# result = generate_application_strategy(DUMMY_USER_DATA)\n",
    "\n",
    "# # Or use the agent with the new tools\n",
    "# from tools import generate_complete_application_strategy\n",
    "\n",
    "# # Add this tool to your agent\n",
    "# tools = [generate_complete_application_strategy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# from workflow_orchestrator import WorkflowOrchestrator, generate_application_strategy\n",
    "\n",
    "# # Configure logging to see the workflow progress\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
